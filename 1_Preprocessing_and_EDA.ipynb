{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62d3e56f",
   "metadata": {},
   "source": [
    "# 1 Preliminary Data Cleaning, Preprocessing and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2385e0",
   "metadata": {},
   "source": [
    "- Author: Jason Truong\n",
    "- Last Modified: September 9, 2022\n",
    "- Email: Jasontruong19@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a88bb5",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Objective](#1Objective)  \n",
    "2. [Preliminary Data Cleaning](#2Preliminary)  \n",
    "    2.1. [Preprocess Duplicated Rows]()  \n",
    "    2.2. [Check NaNs](#)  \n",
    "    2.3. [Preprocess: Duplicated Columns](#)  \n",
    "    2.1. [Preprocessing: 'Overall'](#2_1Overall)  \n",
    "    2.2. [Preprocessing: 'reviewScore'](#2_2Review)  \n",
    "    2.3. [Preprocessing: 'Vote'](#2_3Vote)  \n",
    "    2.4. [Drop duplicates and NaNs](#2_4Drop)  \n",
    "3. [Exploratory Data Analysis](#3EDA)  \n",
    "4. [Simple Modeling](#4Simple_Model)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86751a2c",
   "metadata": {},
   "source": [
    "# 1. Objective<a class ='anchor' id='1Objective'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273c72b6",
   "metadata": {},
   "source": [
    "Reviews provide users with feedback about whether a purchased product is good or not. Reviews play a big role in influencing peoples' decision to purchase a product. In this notebook, the Amazon review data will be loaded in, preproccessed and cleaned for further analysis. The cleaned review data will also be used for a preliminary exploratory data analysis to expose any trends in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bd39bf",
   "metadata": {},
   "source": [
    "# 2. Preliminary Data Cleaning <a class ='anchor' id='2Preliminary'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd532af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages.\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting package\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aa50b6",
   "metadata": {},
   "source": [
    "Since the dataset contains 8.9 million rows of data and is 5.2 gbs, only a small subset of the data will be loaded in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c2b140",
   "metadata": {},
   "source": [
    "Load in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc7464f",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_data = []\n",
    "\n",
    "# Read in the first 2,000,000 rows from the dataset\n",
    "with open('Movies_and_TV.json','r') as metafile:\n",
    "    for x in range(2000000):\n",
    "        review_data.append(json.loads(next(metafile)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b99a64d",
   "metadata": {},
   "source": [
    "Create the dataframe and explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae62880",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.DataFrame(review_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b59171f",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.info(show_counts= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d7c071",
   "metadata": {},
   "source": [
    "There are 12 columns of data with 9 object columns that will been to be convereted to numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493a3e99",
   "metadata": {},
   "source": [
    "## Drop any duplicated rows in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18218a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.drop_duplicates(inplace = True, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d110475",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a5963",
   "metadata": {},
   "source": [
    "1365 entries has been dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f282360",
   "metadata": {},
   "source": [
    "### Check NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4cecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f9095",
   "metadata": {},
   "source": [
    "There are 1497 NaNs in the reviewText column and 394 NaNs in the summary column. This represents a very very small proportion of the data since there are ~ 2 million rows so these rows will just be dropped. Also, the reviewText is the main feature for the machine learning models thus, the rows that have NaNs for ReviewText will essentially be useless for the NLP analysis use case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b18961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.dropna(inplace= True)\n",
    "\n",
    "# Check results\n",
    "review_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79963a76",
   "metadata": {},
   "source": [
    "## Preprocess Duplicated Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e02091",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3f4bb",
   "metadata": {},
   "source": [
    "Looking at the columns, `reviewTime` and `unixReviewTime` may display the same information, a check will be completed to verify if they display the same information. The `reviewerName` does not provide any useful information since there is a unique `reviewerID` for each reviewer. Two reviewers can have the same name but may not be the same person. Thus `reviewerName` will be dropped. The `image` column can be dropped because this project will not deal with image data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0990a66",
   "metadata": {},
   "source": [
    "**Before the `reviewerName` is dropped, it will be compared with the reviewerID column to ensure they contain the same information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f8e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['reviewerID'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b46e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['reviewerName'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc2a360",
   "metadata": {},
   "source": [
    "The `reviewerID` and `reviewerName` column show differrent lengths. The `reviewerName` column contains less information than the `reviewerID` column because users can have the same names but reviewerID is unique. Thus reviewerID should be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942e7d6a",
   "metadata": {},
   "source": [
    "**Verify that the `unixReviewTime` is the same as the `reviewTime` column. First the `reviewTime` will be converted to a datetime type.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9424d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert reviewTime column to datetime type\n",
    "review_df['reviewTime'] = pd.to_datetime(review_df['reviewTime'])\n",
    "\n",
    "# Check results\n",
    "review_df['reviewTime'].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17b60e9",
   "metadata": {},
   "source": [
    "Next, convert the unixReviewTime to a datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0fe71e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert unixReviewTime column to datetime type\n",
    "review_df['unixReviewTime'] = pd.to_datetime(review_df['unixReviewTime'], unit = 's')\n",
    "\n",
    "# Check results\n",
    "review_df['unixReviewTime']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58efe174",
   "metadata": {},
   "source": [
    "Check if the column values are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e1545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(review_df['reviewTime'] == review_df['unixReviewTime']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8088114",
   "metadata": {},
   "source": [
    "All rows of dates are identical so one of them can be dropped. ReviewTime will be dropped."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e02927",
   "metadata": {},
   "source": [
    "**The unnecessary columns can be dropped from the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3ca678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecessary columns\n",
    "review_df.drop(columns = ['reviewTime','reviewerName','image'],inplace = True)\n",
    "\n",
    "# Check results\n",
    "review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34bc338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "review_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf029da2",
   "metadata": {},
   "source": [
    "### Check column `overall`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455abb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['overall'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4713786",
   "metadata": {},
   "source": [
    "It looks like the values for the overall column are contained between 1 and 5 which makes sense since the reviews are out of 5. This column represents the review score so it will be renamed for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column\n",
    "review_df.rename(columns={'overall':'reviewScore'}, inplace = True)\n",
    "\n",
    "# Check results\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8bcce",
   "metadata": {},
   "source": [
    "### Check the column `Vote`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b964c010",
   "metadata": {},
   "source": [
    "For the `vote` column, since the NaN values are essentially no votes which can be represented with 0, the NaN values will be replaced with a zero. There are also commas within the vote that causes problems when converted to an int so they will be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d14314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove commas\n",
    "review_df['vote'] = review_df['vote'].str.replace(r\"\\,\",\"\",regex = True)\n",
    "\n",
    "# Fill NaNs with 0\n",
    "review_df['vote'] = review_df['vote'].fillna(0)\n",
    "\n",
    "# Change datatype to int\n",
    "review_df['vote'] = review_df['vote'].astype('intz')\n",
    "\n",
    "# Check results\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f0886",
   "metadata": {},
   "source": [
    "### Split the reviewTime into date, month and year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b67259",
   "metadata": {},
   "source": [
    "The date column will be split up to determine if the data shows any trends in the days, months and years that the reviews were made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a9a578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the day information\n",
    "review_df['reviewDay'] = review_df['unixReviewTime'].dt.day\n",
    "\n",
    "# Extract the month information\n",
    "review_df['reviewMonth'] = review_df['unixReviewTime'].dt.month\n",
    "\n",
    "# Extract the year information\n",
    "review_df['reviewYear'] = review_df['unixReviewTime'].dt.year\n",
    "\n",
    "# Check results\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810b9b79",
   "metadata": {},
   "source": [
    "Drop the unixReviewTime column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde6eec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.drop(columns ='unixReviewTime', inplace = True)\n",
    "\n",
    "# Check results\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4a434a",
   "metadata": {},
   "source": [
    "### Check the column `style`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5dd8d3",
   "metadata": {},
   "source": [
    "The NaN values in the column `style` will be filled with 'other' since the values is unknown.\n",
    "The column style will be converted to strings so that a duplicate check can be performed for the dataset. (Converting to str, then removing the key for the dictionary is more computationally effective for getting the value in the key-value pair than looping through every individual key and accessing the value. *Note: the latter was tried and took 10 mins for 1 million key-value pairs. The former took <5s.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562dab96",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['style'] = review_df['style'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3428c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change values in the style column from dict to str\n",
    "review_df['style'] = review_df['style'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244f1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the keys in the key-value pair\n",
    "review_df['style'] = review_df['style'].str.replace(r\"{'Format:': ' \",\"\",regex = True)\n",
    "review_df['style'] = review_df['style'].str.replace(r\"'}\",\"\",regex = True)\n",
    "\n",
    "# Check results\n",
    "review_df['style']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6783738",
   "metadata": {},
   "source": [
    "The style column now contains the relavent data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe41e94",
   "metadata": {},
   "source": [
    "Check which styles should be kept by checking the frequency of the different style entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f332737",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_df['style'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1187a4",
   "metadata": {},
   "source": [
    "It looks like the top 5 styles represent the majority of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd25d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the percentage the top 5 styles represent\n",
    "review_df['style'].value_counts().head(5).sum()/review_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1850de18",
   "metadata": {},
   "source": [
    "The top 5 styles represent 99.6% of the data so group everything else to \"other\" and transform this column to one hot encoded variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5d30c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "styles_keep = review_df['style'].value_counts().index[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e1a4c",
   "metadata": {},
   "source": [
    "Replace all the other styles with \"Other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da667d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the style is in the top 5 styles, keep it, else change it to Other\n",
    "review_df['style'] = np.where(review_df['style'].isin(styles_keep), \n",
    "                              review_df['style'], \n",
    "                              \"Other\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b970f041",
   "metadata": {},
   "source": [
    "Check the style column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ade8287",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['style'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42885c5a",
   "metadata": {},
   "source": [
    "The transformation was successful and now there are only 6 style options. The next step is to dummy encode this column and drop the `unknown` column because that column contained NaN values to start off with. One column has to be dropped to ensure that there is no multicollinearity when we use the dummy style columns in the models in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5848f242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use get_dummies function, drop the 'unknown' column and \n",
    "# add the prefix 'style_' to known which column these dummy variables came from\n",
    "\n",
    "style_dummies = pd.get_dummies(review_df['style']).drop(columns = 'Unknown').add_prefix('style_')\n",
    "style_dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e684ce6",
   "metadata": {},
   "source": [
    "The style column was successfully encoded into dummy variables so now combine it with the original dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2630e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df = pd.concat([review_df,style_dummies], axis = 1)\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d28b15",
   "metadata": {},
   "source": [
    "The `style` column can now be dropped since it has been dummy encoded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d660edc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.drop(columns='style', inplace = True)\n",
    "review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1663a1",
   "metadata": {},
   "source": [
    "### Preprocess `verified` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a332a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['verified'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87475181",
   "metadata": {},
   "source": [
    "Since the verified column contains only true and false, the datatype can be changed to int8 for the regression analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399f87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map Trues to 1 and false to 0\n",
    "\n",
    "review_df['verified'] = review_df['verified'].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c329f958",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e044c0",
   "metadata": {},
   "source": [
    "### Narrowing down Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbada03",
   "metadata": {},
   "source": [
    "To narrow in the recommendation capacities, only the movies with > 1000 reviews will be looked at for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba9762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df['asin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ac32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the review occurance for every item \n",
    "# Output the index and the count for # of reviews for every row.\n",
    "review_df.groupby('asin')['asin'].transform('size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2328fa8f",
   "metadata": {},
   "source": [
    "From the above, it can be seen that there are 15,434 unique items from the 2 million rows of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d2d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_subset = review_df.groupby('asin')['asin'].transform('size') >= 100\n",
    "\n",
    "# Check results\n",
    "\n",
    "item_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18318f91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_review_df = review_df[item_subset].copy()\n",
    "\n",
    "# Check results\n",
    "new_review_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805a4eda",
   "metadata": {},
   "source": [
    "Reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ee311",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review_df.reset_index(drop = True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32cefcfc",
   "metadata": {},
   "source": [
    "Check that all items have over 1000 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d26e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_review_df['asin'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e52549e",
   "metadata": {},
   "source": [
    "There are 3744 unique items and all of them have atleast 100 reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeec1fd2",
   "metadata": {},
   "source": [
    "### Create a clean df that only has numeric values for exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34474ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate out the numeric columns\n",
    "numeric_col = list(new_review_df.select_dtypes(\"number\").columns)\n",
    "\n",
    "# Make a new clean dataframe with only the numeric columns\n",
    "clean_df = new_review_df[numeric_col].copy()\n",
    "\n",
    "# Check results\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa990cb",
   "metadata": {},
   "source": [
    "### Preprocess reviewerName and ASIN column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87887ab6",
   "metadata": {},
   "source": [
    "Convert the reviewerName column to a numeric representation using `pd.factorize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae09dd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['reviewer_ID'] = pd.factorize(new_review_df['reviewerID'])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a912a92e",
   "metadata": {},
   "source": [
    "Do the same for the product column (ASIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97870d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['itemID'] = pd.factorize(new_review_df['asin'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fedd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b276e78",
   "metadata": {},
   "source": [
    "The preprocessing for the review data is now complete and the EDA and regression analysis can now be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a537976",
   "metadata": {},
   "source": [
    "## Save the data to a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24962542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed data as one file\n",
    "new_review_df.to_json(r'preprocessed_review.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaf1d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the numeric data as another file\n",
    "clean_df.to_json(r'numeric_review.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7498172",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis <a class ='anchor' id='3EDA'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37f10e",
   "metadata": {},
   "source": [
    "The distribution for each column can be analyzed by plotting the histograms for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf33a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in clean_df.columns:\n",
    "    sns.histplot(x = column, data = clean_df)\n",
    "    plt.title(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3247f2c",
   "metadata": {},
   "source": [
    "Non of the data in the columns look normally distributed. Thus the linear regression model will fit the data poorly. The `reviewScore` is left skewed with most of the data rated at 5. The `unixReviewTime` is also left skewed with a spike in reviews in the unixTime of about 1.35e9. The `vote` column seems to only have one bar close to 0 which could indicate that the majority of the reviews had low votes from other Amazon users and there is a very small percentage of high vote counts. This datetime represents 2012 which could be due to a spike in Amazon usage. The `style` data only contains 1s and 0s since they were dummy encoded thus, it doesn't make sense to look at the histograms for those data. (Histograms are used for continuous data). The `reviewer_ID` and `ItemID` columns are not ordinal data, so looking at a histogram can be misleading. Spikes in the data just mean a person is reviewing a lot of products for `reviewer_ID` and spikes in `itemID` mean that some products are being reviewed a lot of times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07921b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.fromtimestamp(1350000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e0eca",
   "metadata": {},
   "source": [
    "### Check the values in the vote column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f583f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['vote'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc8fa14",
   "metadata": {},
   "source": [
    "Most reviews had 0 votes and many reviews had below 5 votes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b888e655",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['vote'].value_counts().head(1)/clean_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b3a9b",
   "metadata": {},
   "source": [
    "About 79% of the reviews have 0 votes which is an extremely high percentage that will certainly skew the `vote` data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5592caa",
   "metadata": {},
   "source": [
    "Show correlations between different features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281e9d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= [12,8])\n",
    "sns.heatmap(clean_df.corr().round(2), vmin=-1, vmax=1, cmap='coolwarm', annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4143219e",
   "metadata": {},
   "source": [
    "## Conclusion for Preprocessing and EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75467bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "count vectorize meta_data and count vectorize review data separately. Add them together afterwards."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974b53c7",
   "metadata": {},
   "source": [
    "## Read in the clean meta data and combine it with the clean review data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624bebb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# meta_df = pd.read_csv('clean_meta.csv')\n",
    "# meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be4d48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean_df['asin'] = review_df['asin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34668fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = pd.merge(clean_df, meta_df,  how='left', left_on='asin', right_on = 'asin')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5e820f3ddc028a719ffe50e7d80dd01658ce1fe998d4f6f388d9b09d11d3d164"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
